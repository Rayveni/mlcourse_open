{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Авторы материала: аспирант Мехмата МГУ Евгений Колмаков, программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 3. Опциональная часть \n",
    "## <center> Реализация алгоритма построения дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Необходимо реализовать класс `DecisionTree`**\n",
    "\n",
    "**Спецификация:**\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    `min_samples_split` - минимальное число объектов в вершине, при котором происходит её разбиение (по умолчанию - 2); \n",
    "    `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', для регрессии - 'variance' или 'mad_median'; \n",
    "    по умолчанию - 'gini');\n",
    "    \n",
    "    Функционал, значение которого максимизируется для поиска оптимального разбиения в данной вершине имеет вид\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    где $X$ - выборка, находящаяся в текущей вершине, $X_l$ и $X_r$ - разбиение выборки $X$ на две части \n",
    "    по предикату $[x_j < t]$, а $F(X)$ -критерий разбиения.\n",
    "    \n",
    "    Для классификации: пусть $p_i$ - доля объектов $i$-го класса в выборке $X$.\n",
    "    \n",
    "    'gini': Неопределенность Джини $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Энтропия $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    Для регрессии: $y_j = y(x_j)$ - ответ на объекте $x_j$, $y = (y_1, \\dots, y_{|X|})$ - вектор ответов.\n",
    "    \n",
    "    'variance': Дисперсия (среднее квадратичное отклонение от среднего) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Среднее отклонение от медианы $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- класс имеет методы `fit`, `predict` и `predict_proba`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `DecisionTree`, представляющий собой решающее дерево, обученное по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict_proba` принимает матрицу объектов `X` и возвращает матрицу `P` размера `X.shape[0] x K`, где `K` - число классов, такую что $p_{ij}$ есть вероятность принадлежности объекта, заданного $i$-ой строкой матрицы X к классу $j \\in \\{1, \\dots, K\\}$.\n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов; в случае классификации - это \n",
    "    наиболее многочисленный класс в листе, в который попал объект, а в случае регрессии - среднее значение ответов по \n",
    "    всем объектам этого листа;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(s):\n",
    "    y=np.mean(s)\n",
    "    print([(y -x)**2 for x in s])\n",
    "    return np.mean([(y -x)**2 for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(y):    \n",
    "    res = 0\n",
    "    val, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts/len(s)\n",
    "    for p in freqs:\n",
    "        if p != 0.0:\n",
    "            res = res- p * np.log2(p)\n",
    "    return res\n",
    "\n",
    "def gini(y):\n",
    "    res = 0\n",
    "    val, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts/len(s)\n",
    "    freqs=freqs**2\n",
    "    return 1-sum(freqs)\n",
    "\n",
    "def variance(y):\n",
    "     mean=np.mean(y)\n",
    "     y_sum=np.sum((x-mean)**2 for x in y)\n",
    "     return y_sum/len(y)\n",
    "\n",
    "def mad_median(y):\n",
    "     median=np.mean(y)\n",
    "     y_sum=np.sum((x-median)**2 for x in y)\n",
    "     return y_sum/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "method(221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.array([1,0,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True, False,  True,  True], dtype=bool),\n",
       " array([ True, False,  True, False, False], dtype=bool))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~(a==1),(a==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        self.criterion=function_by_name(criterion)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pass\n",
    "    def mutual_information(self,y, x,t):\n",
    "        \n",
    "        res = self.criterion(y)\n",
    "        #x  is the attribute we are using for splitting that assumes the values {0, 1}\n",
    "        # We partition x, according to attribute values x_i\n",
    "        val, counts = np.unique(x, return_counts=True)\n",
    "        freqs = counts/len(x)\n",
    "        # We calculate a weighted average of the entropy\n",
    "        res=\n",
    "        for p, v in list(zip(freqs, val)):\n",
    "            res -= p * self.criterion(y[x == v])\n",
    "\n",
    "        return res\n",
    "\n",
    "    def function_by_name(method_name):\n",
    "        possibles = globals().copy()\n",
    "        possibles.update(locals())\n",
    "        return possibles.get(method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функционал, значение которого максимизируется для поиска оптимального разбиения в данной вершине имеет вид\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование реализованного алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_digits` загрузите датасет `digits`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=17`. Попробуйте обучить неглубокие решающие деревья и убедитесь, что критерии gini и entropy дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'digits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-077a50ed8b46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload_digits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'digits'"
     ]
    }
   ],
   "source": [
    "load_digits.digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации (`GridSearchCV`) подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - range(3, 11), а для criterion - {'gini', 'entropy'}. Критерий качества `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `accuracy` для критериев `gini` и `entropy` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберите верные утверждения:**\n",
    "1. Оптимальное значение max_depth для каждого критерия достигается внутри отрезка [3, 10] (то есть на отрезке [4, 9]).\n",
    "2. На отрезке [3, 10] построенные графики не пересекаются.\n",
    "3. На отрезке [3, 10] построенные графики пересекаются ровно один раз.\n",
    "4. Наилучшее качество при max_depth на интервале [3, 10] достигается на критерии gini.\n",
    "5. Хотя бы для одного из критериев значение accuracy строго возрастает с ростом значения max_depth на интервале [3, 10]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чему равны найденные оптимальные значения параметров max_depth и criterion?**\n",
    "1. max_depth = 4, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 3, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя найденные оптимальные значения max_depth и criterion, обучите решающее дерево на X_train, y_train и вычислите вероятности принадлежности к классам для X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полученной матрицы вычислите усредненные по всем объектам из `X_test` значения вероятностей принадлежности к классам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Чему равна максимальная вероятность в полученном векторе?\n",
    "1. 0.11218791\n",
    "2. 0.11783761\n",
    "3. 1.0\n",
    "4. 0.0875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_boston` загрузите датасет `boston`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=17`. Попробуйте обучить неглубокие регрессионные деревья и убедитесь, что критерии `variance` и `mad_median` дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - `range(2, 9)`, а для `criterion` - {'variance', 'mad_median'}. Критерий качества `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `neg_mean_squared_error` для критериев `variance` и `mad_median` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберите верные утверждения:**\n",
    "1. На отрезке [2, 8] построенные графики не пересекаются.\n",
    "2. На отрезке [2, 8] построенные графики пересекаются ровно один раз.\n",
    "3. Оптимальное значение max_depth для каждого из критериев достигается на границе отрезка [2, 8].\n",
    "4. Наилучшее качество при max_depth in range(2, 9) достигается на критерии variance.\n",
    "5. График качества ровно для одного из критериев имеет явно выраженный пик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чему равны найденные оптимальные значения параметров `max_depth` и `criterion`?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 8, criterion = 'variance';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data=[['slashdot','USA','yes',18,'None'],\n",
    "        ['google','France','yes',23,'Premium'],\n",
    "        ['reddit','USA','yes',24,'Basic'],\n",
    "        ['kiwitobes','France','yes',23,'Basic'],\n",
    "        ['google','UK','no',21,'Premium'],\n",
    "        ['(direct)','New Zealand','no',12,'None'],\n",
    "        ['(direct)','UK','no',21,'Basic'],\n",
    "        ['google','USA','no',24,'Premium'],\n",
    "        ['slashdot','France','yes',19,'None'],\n",
    "        ['reddit','USA','no',18,'None'],\n",
    "        ['google','UK','no',18,'None'],\n",
    "        ['kiwitobes','UK','no',19,'None'],\n",
    "        ['reddit','New Zealand','yes',12,'Basic'],\n",
    "        ['slashdot','UK','no',21,'None'],\n",
    "        ['google','UK','yes',18,'Basic'],\n",
    "        ['kiwitobes','France','yes',19,'Basic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decisionnode:\n",
    "    def __init__(self,col=-1,value=None,results=None,tb=None,fb=None):\n",
    "        self.col=col # column index of criteria being tested\n",
    "        self.value=value # vlaue necessary to get a true result\n",
    "        self.results=results # dict of results for a branch, None for everything except endpoints\n",
    "        self.tb=tb # true decision nodes \n",
    "        self.fb=fb # false decision nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divides a set on a specific column. Can handle numeric or nominal values\n",
    "\n",
    "def divideset(rows,column,value):\n",
    "    # Make a function that tells us if a row is in the first group \n",
    "    # (true) or the second group (false)\n",
    "    split_function=None\n",
    "    # for numerical values\n",
    "    if isinstance(value,int) or isinstance(value,float):\n",
    "        split_function=lambda row:row[column]>=value\n",
    "    # for nominal values\n",
    "    else:\n",
    "        split_function=lambda row:row[column]==value\n",
    "   \n",
    "   # Divide the rows into two sets and return them\n",
    "    set1=[row for row in rows if split_function(row)] # if split_function(row) \n",
    "    set2=[row for row in rows if not split_function(row)]\n",
    "    return (set1,set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previously defined my_data let's split our data by users in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['slashdot', 'USA', 'yes', 18, 'None'],\n",
       "  ['reddit', 'USA', 'yes', 24, 'Basic'],\n",
       "  ['google', 'USA', 'no', 24, 'Premium'],\n",
       "  ['reddit', 'USA', 'no', 18, 'None']],\n",
       " [['google', 'France', 'yes', 23, 'Premium'],\n",
       "  ['kiwitobes', 'France', 'yes', 23, 'Basic'],\n",
       "  ['google', 'UK', 'no', 21, 'Premium'],\n",
       "  ['(direct)', 'New Zealand', 'no', 12, 'None'],\n",
       "  ['(direct)', 'UK', 'no', 21, 'Basic'],\n",
       "  ['slashdot', 'France', 'yes', 19, 'None'],\n",
       "  ['google', 'UK', 'no', 18, 'None'],\n",
       "  ['kiwitobes', 'UK', 'no', 19, 'None'],\n",
       "  ['reddit', 'New Zealand', 'yes', 12, 'Basic'],\n",
       "  ['slashdot', 'UK', 'no', 21, 'None'],\n",
       "  ['google', 'UK', 'yes', 18, 'Basic'],\n",
       "  ['kiwitobes', 'France', 'yes', 19, 'Basic']])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divideset(my_data,1,'USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granted this is a small samples of data, country of orgin doesn't seem to be a good variable to split on at this point as we still have a good representation/mix of subscription outcomes in both sets above (None, Basic, Premium).\n",
    "We need a formalized manner to assess how mixed a result set is in order to properly check the outcome of spliting on each variable. When constructing our root node we should chose a variable that creates two sets with the least possible amount of mixing. To start let's create a function to count the occurences of the outcomes in each set. We'll use this function later on inside other functions to measure how mixed a set is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create counts of possible results (last column of each row is the result)\n",
    "def uniquecounts(rows):\n",
    "    results={}\n",
    "    for row in rows:\n",
    "        # The result is the last column\n",
    "        r=row[len(row)-1]\n",
    "        if r not in results: results[r]=0\n",
    "        results[r]+=1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def uniquecounts_dd(rows):\n",
    "    results = defaultdict(lambda: 0)\n",
    "    for row in rows:\n",
    "        r = row[len(row)-1]\n",
    "        results[r]+=1\n",
    "    return dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Basic': 6, 'None': 7, 'Premium': 3},\n",
       " 'Same output',\n",
       " {'Basic': 6, 'None': 7, 'Premium': 3})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniquecounts(my_data),'Same output', uniquecounts_dd(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entropy is the sum of p(x)log(p(x)) across all the different possible results\n",
    "def entropy(rows):\n",
    "    from math import log\n",
    "    log2=lambda x:log(x)/log(2)  \n",
    "    results=uniquecounts(rows)\n",
    "    # Now calculate the entropy\n",
    "    ent=0.0\n",
    "    for r in results.keys():\n",
    "        # current probability of class\n",
    "        p=float(results[r])/len(rows) \n",
    "        ent=ent-p*log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5052408149441479"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially entropy is higher the more mixed up the groups or outcomes of subscription is. Trying the function on a data set where the outcomes either None or Basic should result in a smaller number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852281360342516"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2=[['slashdot','USA','yes',18,'None'],\n",
    "        ['google','France','yes',23,'None'],\n",
    "        ['reddit','USA','yes',24,'Basic'],\n",
    "        ['kiwitobes','France','yes',23,'Basic'],\n",
    "        ['google','UK','no',21,'None'],\n",
    "        ['(direct)','New Zealand','no',12,'None'],\n",
    "        ['(direct)','UK','no',21,'Basic']]\n",
    "\n",
    "entropy(my_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a method of assessing entropy. The next step in building our tree will involve assessing the success of each variable's ability to split the dataset. In other words we're attempting to identify the feature that best splits the target class into the purest children nodes. These pure nodes would not contain a mix of output classes, in this case subscription level (None, Basic, Premium).<br>\n",
    "We'll start by calculating the entropy of the entire data set then dividing the group by all the possible outcomes for each attribute. We determine the best attribute to divide on by calculating information gain (Entropy before - Entropy after). Again more info in my more detailed post on entropy here: http://kldavenport.com/a-real-world-introduction-to-information-entropy/.<br>\n",
    "**Caveats**: Information gain is generally a good measure for deciding the relevance of an attribute, but there are some distinct shortcomings. One case is when information gain is applied to variabless that take on a large number of unique values. This is a concern not necessarily from a pure variance perspective, rather that the variable is too descriptive of the current observations..<br>\n",
    "**High mutual information** indicates a large reduction in uncertainty, credit card numbers or street addresss variables in a dataset uniquely identify a customer. These variables provide a great deal of identifying information if we are trying to predict a customer, but will not generalize well to unobserved/trained-on instances (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildtree(rows, scorefun=entropy):\n",
    "    if len(rows) == 0: return decisionnode()\n",
    "    current_score = scorefun(rows)\n",
    "\n",
    "    best_gain = 0.0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "\n",
    "    column_count = len(rows[0]) - 1\t# last column is result\n",
    "    for col in range(0, column_count):\n",
    "        # find different values in this column\n",
    "        column_values = set([row[col] for row in rows])\n",
    "\n",
    "        # for each possible value, try to divide on that value\n",
    "        for value in column_values:\n",
    "            set1, set2 = divideset(rows, col, value)\n",
    "\n",
    "            # Information gain\n",
    "            p = float(len(set1)) / len(rows)\n",
    "            gain = current_score - p*scorefun(set1) - (1-p)*scorefun(set2)\n",
    "            if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                best_gain = gain\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1, set2)\n",
    "\n",
    "    if best_gain > 0:\n",
    "        trueBranch = buildtree(best_sets[0])\n",
    "        falseBranch = buildtree(best_sets[1])\n",
    "        return decisionnode(col=best_criteria[0], value=best_criteria[1],\n",
    "                tb=trueBranch, fb=falseBranch)\n",
    "    else:\n",
    "        return decisionnode(results=uniquecounts(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a function that returns a trained decision tree. We can print a rudimentary tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtree(tree,indent=''):\n",
    "    # Is this a leaf node?\n",
    "    if tree.results!=None:\n",
    "        print (str(tree.results))\n",
    "    else:\n",
    "        # Print the criteria\n",
    "        print( 'Column ' + str(tree.col)+' : '+str(tree.value)+'? ')\n",
    "\n",
    "        # Print the branches\n",
    "        print (indent+'True->',)\n",
    "        printtree(tree.tb,indent+'  ')\n",
    "        print (indent+'False->',)\n",
    "        printtree(tree.fb,indent+'  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['slashdot', 'USA', 'yes', 18, 'None'],\n",
       " ['google', 'France', 'yes', 23, 'Premium'],\n",
       " ['reddit', 'USA', 'yes', 24, 'Basic']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing a few rows of our dataset for context\n",
    "my_data[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When printing the tree we see that the root node checks if column 0 contains 'google'. If the condition is met (condition is True) we then move on to see that anyone that was referred from Google will purchase a subscription (Basic or Premium) if they view 21 pages or more and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 : google? \n",
      "True->\n",
      "Column 3 : 21? \n",
      "  True->\n",
      "{'Premium': 3}\n",
      "  False->\n",
      "Column 2 : no? \n",
      "    True->\n",
      "{'None': 1}\n",
      "    False->\n",
      "{'Basic': 1}\n",
      "False->\n",
      "Column 0 : slashdot? \n",
      "  True->\n",
      "{'None': 3}\n",
      "  False->\n",
      "Column 2 : no? \n",
      "    True->\n",
      "Column 3 : 21? \n",
      "      True->\n",
      "{'Basic': 1}\n",
      "      False->\n",
      "{'None': 3}\n",
      "    False->\n",
      "{'Basic': 4}\n"
     ]
    }
   ],
   "source": [
    "printtree(buildtree(my_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
